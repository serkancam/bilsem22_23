{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"train\")\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models,optimizers\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(180,180,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512,activation=\"relu\"))\n",
    "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 178, 178, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 89, 89, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 87, 87, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 41, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               5308928   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 5,550,273\n",
      "Trainable params: 5,550,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# birincil y√∂ntem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "data batch shape: (32, 180, 180, 3)\n",
      "labels batch shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_dir=\"/media/serkancam/yedek/Calismalar/python/derin_ogrenme/kodlarim/dogs-vs-cats/cats_vs_dogs_small/train\"\n",
    "validation_dir=\"/media/serkancam/yedek/Calismalar/python/derin_ogrenme/kodlarim/dogs-vs-cats/cats_vs_dogs_small/validation\"\n",
    "train_datagen =  ImageDataGenerator(rescale=1./255,\n",
    "                                    # rotation_range=40,\n",
    "                                    # width_shift_range=0.2,\n",
    "                                    # height_shift_range=0.2,\n",
    "                                    # shear_range=0.2,\n",
    "                                    # zoom_range=0.2,\n",
    "                                    # horizontal_flip=True                                    \n",
    "                                    )\n",
    "test_datagen =  ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "                                train_dir,\n",
    "                                target_size=(180,180),\n",
    "                                batch_size=32,\n",
    "                                class_mode=\"binary\"\n",
    "                                )\n",
    "validation_generator=train_datagen.flow_from_directory(\n",
    "                                validation_dir,\n",
    "                                target_size=(180,180),\n",
    "                                batch_size=32,\n",
    "                                class_mode=\"binary\"\n",
    "                                )\n",
    "\n",
    "for data_batch,labels_batch in train_generator:\n",
    "    print(\"data batch shape:\",data_batch.shape)\n",
    "    print(\"labels batch shape:\",labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(train_generator))\n",
    "print(train_generator.batch_size)\n",
    "print(len(validation_generator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(\n",
    "    train_generator,\n",
    "    # steps_per_epoch=63,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    # validation_steps=32,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"acc\"]\n",
    "val_accuracy = history.history[\"val_acc\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
